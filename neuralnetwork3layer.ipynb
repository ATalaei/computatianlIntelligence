{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464131e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#USE IT JUST FOR MAKE LABELS TO ONEHOT VECTOR\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import random\n",
    "# PLT_DATA=np.array()\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "\n",
    "def cross_entropy(y_true, y_pred):\n",
    "    epsilon = 1e-12\n",
    "    num_examples = y_true.shape[0]\n",
    "    loss = -np.sum(y_true * np.log(y_pred + epsilon)) / num_examples\n",
    "    return loss\n",
    "\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "\n",
    "    return x * (1 - x)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    acc = np.mean(y_true == y_pred)\n",
    "    return acc\n",
    "\n",
    "\n",
    "def minibatch_GD_train(X_train, y_train, learning_rate, batch_size, num_epochs):\n",
    "\n",
    "    np.random.seed(0)\n",
    "    weights1 = np.random.randn(4, 10)\n",
    "    weights2 = np.random.randn(10, 10)\n",
    "    weights3 = np.random.randn(10, 3)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        permutation = np.random.permutation(X_train.shape[0])\n",
    "        X_train = X_train[permutation]\n",
    "        y_train = y_train[permutation]\n",
    "\n",
    "        for i in range(0, X_train.shape[0], batch_size):\n",
    "            # get batch\n",
    "            X_batch = X_train[i:i + batch_size]\n",
    "            y_batch = y_train[i:i + batch_size]\n",
    "\n",
    "            z1 = np.dot(X_batch, weights1)\n",
    "            a1 = sigmoid(z1)\n",
    "            z2 = np.dot(a1, weights2)\n",
    "            a2 = sigmoid(z2)\n",
    "            z3 = np.dot(a2, weights3)\n",
    "            y_pred = softmax(z3)\n",
    "            y_batch = to_categorical(y_batch)\n",
    "            loss = cross_entropy(y_batch, y_pred)\n",
    "            acc = accuracy(y_batch, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            dL_dy_pred = y_pred - y_batch\n",
    "            dL_dz3 = dL_dy_pred\n",
    "            dL_da2 = np.dot(dL_dz3, weights3.T)\n",
    "            dL_dz2 = dL_da2 * sigmoid_derivative(a2)\n",
    "            dL_da1 = np.dot(dL_dz2, weights2.T)\n",
    "            dL_dz1 = dL_da1 * sigmoid_derivative(a1)\n",
    "\n",
    "\n",
    "            weights3 -= learning_rate * np.dot(a2.T, dL_dz3)\n",
    "            weights2 -= learning_rate * np.dot(a1.T, dL_dz2)\n",
    "            weights1 -= learning_rate * np.dot(X_batch.T, dL_dz1)\n",
    "\n",
    "    return weights1, weights2, weights3\n",
    "\n",
    "\n",
    "\n",
    "def SGD_train(X_train, y_train, learning_rate, num_epochs):\n",
    "    # initialize weights\n",
    "    np.random.seed(0)\n",
    "    weights1 = np.random.randn(4, 10)\n",
    "    weights2 = np.random.randn(10, 10)\n",
    "    weights3 = np.random.randn(10, 3)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        permutation = np.random.permutation(X_train.shape[0])\n",
    "        X_train = X_train[permutation]\n",
    "        y_train = y_train[permutation]\n",
    "\n",
    "        for i in range(0, X_train.shape[0]):\n",
    "\n",
    "            X_example = X_train[i:i+1]\n",
    "            y_example = y_train[i:i+1]\n",
    "            z1 = np.dot(X_example, weights1)\n",
    "            a1 = sigmoid(z1)\n",
    "            z2 = np.dot(a1, weights2)\n",
    "            a2 = sigmoid(z2)\n",
    "            z3 = np.dot(a2, weights3)\n",
    "            y_pred = softmax(z3)\n",
    "            y_example = to_categorical(y_example,num_classes=3)\n",
    "            loss = cross_entropy(y_example, y_pred)\n",
    "            acc = accuracy(y_example, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            dL_dy_pred = y_pred - y_example\n",
    "            dL_dz3 = dL_dy_pred\n",
    "            dL_da2 = np.dot(dL_dz3, weights3.T)\n",
    "            dL_dz2 = dL_da2 * sigmoid_derivative(a2)\n",
    "            dL_da1 = np.dot(dL_dz2, weights2.T)\n",
    "            dL_dz1 = dL_da1 * sigmoid_derivative(a1)\n",
    "\n",
    "\n",
    "            weights3 -= learning_rate * np.dot(a2.T, dL_dz3)\n",
    "            weights2 -= learning_rate * np.dot(a1.T, dL_dz2)\n",
    "            weights1 -= learning_rate * np.dot(X_example.T, dL_dz1)\n",
    "\n",
    "\n",
    "    return weights1, weights2, weights3\n",
    "\n",
    "\n",
    "\n",
    "def GD_train(X_train, y_train, test_labels, test_data, learning_rate, num_epochs, faultes=None):\n",
    "    # np.random.seed(165495)\n",
    "    # np.random.seed(20000)\n",
    "    np.random.seed(152)\n",
    "    weights1 = np.random.randn(4, 10)\n",
    "    weights2 = np.random.randn(10, 10)\n",
    "    weights3 = np.random.randn(10, 3)\n",
    "    y_train = to_categorical(y_train, num_classes=3)\n",
    "    accuracies = []\n",
    "    faultes=[]\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "            z1 = np.dot(X_train, weights1)\n",
    "            a1 = sigmoid(z1)\n",
    "            z2 = np.dot(a1, weights2)\n",
    "            a2 = sigmoid(z2)\n",
    "            z3 = np.dot(a2, weights3)\n",
    "            y_pred = softmax(z3)\n",
    "            loss = cross_entropy(y_train, y_pred)\n",
    "            acc = accuracy(y_train, y_pred)\n",
    "\n",
    "\n",
    "            dL_dy_pred = y_pred - y_train\n",
    "            dL_dz3 = dL_dy_pred\n",
    "            dL_da2 = np.dot(dL_dz3, weights3.T)\n",
    "            dL_dz2 = dL_da2 * sigmoid_derivative(a2)\n",
    "            dL_da1 = np.dot(dL_dz2, weights2.T)\n",
    "            dL_dz1 = dL_da1 * sigmoid_derivative(a1)\n",
    "\n",
    "\n",
    "            weights3 -= learning_rate * np.dot(a2.T, dL_dz3)\n",
    "            weights2 -= learning_rate * np.dot(a1.T, dL_dz2)\n",
    "            weights1 -= learning_rate * np.dot(X_train.T, dL_dz1)\n",
    "\n",
    "            y_test_onehot = to_categorical(test_labels)\n",
    "            z1 = np.dot(test_data, weights1)\n",
    "            a1 = sigmoid(z1)\n",
    "            z2 = np.dot(a1, weights2)\n",
    "            a2 = sigmoid(z2)\n",
    "            z3 = np.dot(a2, weights3)\n",
    "            y_pred = softmax(z3)\n",
    "            y_pred_one_hot = np.argmax(y_pred, axis=1)\n",
    "            y_pred_one_hot = to_categorical(y_pred_one_hot)\n",
    "            test_acc = accuracy(y_test_onehot, y_pred_one_hot)\n",
    "            test_loss = cross_entropy(y_test_onehot, y_pred_one_hot)\n",
    "            accuracies.append(test_acc)\n",
    "            faultes.append(1-test_acc)\n",
    "\n",
    "    plt.plot(accuracies)\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\n",
    "    plt.plot(faultes)\n",
    "    plt.title('faultes over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('fualtes')\n",
    "    plt.show()\n",
    "\n",
    "    return weights1, weights2, weights3\n",
    "\n",
    "\n",
    "#################################################\n",
    "#Q2_A:reading and normalizing and division t0 80% 20%\n",
    "##################################################\n",
    "\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "labels = iris.target\n",
    "random.seed(42)\n",
    "data_indices = list(range(len(data)))\n",
    "random.shuffle(data_indices)\n",
    "split_point = int(0.8 * len(data))\n",
    "train_indices = data_indices[:split_point]\n",
    "test_indices = data_indices[split_point:]\n",
    "X = data[train_indices]#train_set\n",
    "y = labels[train_indices]\n",
    "test_data = data[test_indices]\n",
    "test_labels = labels[test_indices]\n",
    "#normalization\n",
    "test_data = (test_data - np.mean(test_data, axis=0)) / np.std(test_data, axis=0)\n",
    "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "X = X.astype(np.float64)\n",
    "y = y.astype(np.float64)\n",
    "test_data = test_data.astype(np.float64)\n",
    "test_labels = test_labels.astype(np.float64)\n",
    "\n",
    "\n",
    "\n",
    "###using SGD_function########\n",
    "#############################\n",
    "weights1, weights2, weights3 = SGD_train(X, y, learning_rate=0.01, num_epochs=50)\n",
    "\n",
    "y_test_onehot = to_categorical(test_labels)\n",
    "z1 = np.dot(test_data, weights1)\n",
    "a1 = sigmoid(z1)\n",
    "z2 = np.dot(a1, weights2)\n",
    "a2 = sigmoid(z2)\n",
    "z3 = np.dot(a2, weights3)\n",
    "y_pred = softmax(z3)\n",
    "y_pred_one_hot = np.argmax(y_pred, axis=1)\n",
    "y_pred_one_hot=to_categorical(y_pred_one_hot)\n",
    "test_acc = accuracy(y_test_onehot, y_pred_one_hot)\n",
    "test_loss = cross_entropy(y_test_onehot, y_pred_one_hot)\n",
    "print(\"\\nSGD_train:\")\n",
    "print(f'Test accuracy: {test_acc:.2f}')\n",
    "print(f'Test loss: {test_loss:.4f}')\n",
    "\n",
    "\n",
    "###using minibatch_function########\n",
    "#############################\n",
    "weights1, weights2, weights3 = minibatch_GD_train(X, y,learning_rate=0.01, batch_size=32, num_epochs=50)\n",
    "\n",
    "y_test_onehot = to_categorical(test_labels)\n",
    "z1 = np.dot(test_data, weights1)\n",
    "a1 = sigmoid(z1)\n",
    "z2 = np.dot(a1, weights2)\n",
    "a2 = sigmoid(z2)\n",
    "z3 = np.dot(a2, weights3)\n",
    "y_pred = softmax(z3)\n",
    "y_pred_one_hot = np.argmax(y_pred, axis=1)\n",
    "y_pred_one_hot=to_categorical(y_pred_one_hot)\n",
    "test_acc = accuracy(y_test_onehot, y_pred_one_hot)\n",
    "test_loss = cross_entropy(y_test_onehot, y_pred_one_hot)\n",
    "print(\"\\nMinibatch_GD_train:\")\n",
    "print(f'Test accuracy: {test_acc:.2f}')\n",
    "print(f'Test loss: {test_loss:.4f}')\n",
    "\n",
    "\n",
    "###using GD_function########\n",
    "#############################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weights1, weights2, weights3 = GD_train(X, y,test_labels,test_data, learning_rate=0.01, num_epochs=100)\n",
    "\n",
    "\n",
    "y_test_onehot = to_categorical(test_labels)\n",
    "z1 = np.dot(test_data, weights1)\n",
    "a1 = sigmoid(z1)\n",
    "z2 = np.dot(a1, weights2)\n",
    "a2 = sigmoid(z2)\n",
    "z3 = np.dot(a2, weights3)\n",
    "y_pred = softmax(z3)\n",
    "y_pred_one_hot = np.argmax(y_pred, axis=1)\n",
    "y_pred_one_hot=to_categorical(y_pred_one_hot)\n",
    "test_acc = accuracy(y_test_onehot, y_pred_one_hot)\n",
    "test_loss = cross_entropy(y_test_onehot, y_pred_one_hot)\n",
    "print(\"\\nGD_train:\")\n",
    "print(f'Test accuracy: {test_acc:.2f}')\n",
    "print(f'Test loss: {test_loss:.4f}')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
